{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66c44d7-5af9-49fc-9bc4-39b735f2ecd3",
   "metadata": {},
   "source": [
    "# $\\mu$ girls - Modeling\n",
    "\n",
    "- Rani Misra, Cheryl Chiu, Abigail Davis, Kashfia Sharmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ca0ad7-6168-4047-98e3-2b6f71f752ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment  Gold Standard  num_caps  \\\n",
      "0  For information regarding public services to b...     Technology         0   \n",
      "1  Improve and fund public transportation to allo...  Public Safety         0   \n",
      "2  More access to info like mutual aid and having...  Public Safety         0   \n",
      "3  Greater access to transportation and more sola...     Technology         0   \n",
      "4  Create a 'NYC time square' like location downt...     Technology         1   \n",
      "\n",
      "   num_exclamations  has_repeated_chars  \n",
      "0                 0                   0  \n",
      "1                 0                   0  \n",
      "2                 0                   0  \n",
      "3                 0                   0  \n",
      "4                 0                   0  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Both       0.71      0.29      0.42        17\n",
      "      Neither       0.75      0.87      0.81        79\n",
      "Public Safety       0.50      0.33      0.40         6\n",
      "   Technology       0.82      0.82      0.82        98\n",
      "\n",
      "     accuracy                           0.78       200\n",
      "    macro avg       0.70      0.58      0.61       200\n",
      " weighted avg       0.78      0.78      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Personal Annotations.csv\", usecols=[\"Comment\", \"Gold Standard\"])\n",
    "df['Comment'] = df['Comment'].fillna('').astype(str)\n",
    "\n",
    "# Feature engineering based on text\n",
    "df['num_caps'] = df['Comment'].apply(lambda x: sum(1 for word in x.split() if word.isupper()))\n",
    "df['num_exclamations'] = df['Comment'].apply(lambda x: x.count('!'))\n",
    "df['has_repeated_chars'] = df['Comment'].apply(lambda x: 1 if re.search(r'(.)\\1{2,}', x) else 0)\n",
    "\n",
    "# Print the first few rows to confirm\n",
    "print(df.head())\n",
    "\n",
    "# Vectorize the text using Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000)  # You can adjust the max_features as needed\n",
    "X_text = vectorizer.fit_transform(df['Comment'])\n",
    "\n",
    "# Combine the features: numerical features and the Bag of Words features\n",
    "X_numeric = df[['num_caps', 'num_exclamations', 'has_repeated_chars']]\n",
    "X_combined = np.hstack((X_numeric, X_text.toarray()))\n",
    "\n",
    "# Target variable\n",
    "y = df['Gold Standard']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c0bb03-7c11-4b6f-b4c6-4885d21b87cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (mean): 0.7109864121591349\n",
      "Recall (mean): 0.7140000000000001\n",
      "F1-Score (mean): 0.6939051401499264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, precision_recall_fscore_support\n",
    "\n",
    "pipeline = make_pipeline(vectorizer, model)\n",
    "\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return {'precision': metrics[0], 'recall': metrics[1], 'f1': metrics[2]}\n",
    "\n",
    "scoring = {\n",
    "    'precision': make_scorer(lambda y_true, y_pred: custom_scorer(y_true, y_pred)['precision']),\n",
    "    'recall': make_scorer(lambda y_true, y_pred: custom_scorer(y_true, y_pred)['recall']),\n",
    "    'f1': make_scorer(lambda y_true, y_pred: custom_scorer(y_true, y_pred)['f1']),\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(pipeline, df['Comment'], df['Gold Standard'], cv=5, scoring=scoring)\n",
    "\n",
    "print(\"Precision (mean):\", np.mean(cv_results['test_precision']))\n",
    "print(\"Recall (mean):\", np.mean(cv_results['test_recall']))\n",
    "print(\"F1-Score (mean):\", np.mean(cv_results['test_f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d039eba-ea64-42d6-9a3a-59769a656281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 1, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'}\n",
      "Best F1 Score: 0.6939051401499264\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Both       1.00      0.88      0.93        89\n",
      "      Neither       0.92      0.98      0.95       347\n",
      "Public Safety       1.00      0.84      0.91        61\n",
      "   Technology       0.98      0.97      0.97       503\n",
      "\n",
      "     accuracy                           0.96      1000\n",
      "    macro avg       0.97      0.92      0.94      1000\n",
      " weighted avg       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline to include vectorization and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english', max_features=1000)),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'logreg__penalty': ['l2'],           \n",
    "    'logreg__solver': ['lbfgs', 'saga']   # Solvers that support multi-class classification\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='f1_weighted',  # Focus on F1 score for imbalanced classes\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(df['Comment'], df['Gold Standard'])\n",
    "\n",
    "# Display the best parameters and the corresponding F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(df['Comment'])\n",
    "\n",
    "# Evaluate using the classification report\n",
    "print(classification_report(df['Gold Standard'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ec74b5-8592-438a-afb0-55079e33545f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Best_Model_Predictons.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the comments, gold standard, and predictions\n",
    "output_df = pd.DataFrame({\n",
    "    'Comment': df['Comment'],  # Use the original comments from the DataFrame\n",
    "    'Gold Standard': df['Gold Standard'],  # Gold standard values (true labels)\n",
    "    'Prediction': y_pred  # Predictions from the best model\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "output_df.to_csv('Best_Model_Predictons.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'Best_Model_Predictons.csv' has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
